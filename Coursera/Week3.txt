Exploratory Data Analysis
In this module, we're going to cover the basics of Exploratory Data Analysis using Python. Exploratory data analysis or in short, 
EDA is an approach to analyze data in order to summarize main characteristics of the data, gain better understanding of the data set, uncover relationships between different variables, 
and extract important variables for the problem we're trying to solve. 
The main question we are trying to answer in this module is, what are the characteristics that had the most impact on the car price? 
We will be going through a couple of different useful exploratory data analysis techniques in order to answer this question. 
In this module, you will learn about descriptive statistics, which describe basic features of a data set, and obtain a short summary about the sample and measures of the data; 
basic of grouping data using GroupBuy, and how this can help to transform our data set; ANOVA, the analysis of variance, 
a statistical method in which the variation in a set of observations is divided into distinct components; the correlation between different variables; 
and lastly, advance correlation, where we'll introduce you to various correlations statistical methods namely, Pearson correlation, and correlation heatmaps.

Descriptive Statistics
we'll be talking about descriptive statistics. When you begin to analyze data, It's important to first explore your data before you spend time building complicated models. 
One easy way to do so is to calculate some descriptive statistics for your data. Descriptive statistical analysis helps to describe basic features of a dataset
and obtains a short summary about the sample and measures of the data. Let's show you a couple different useful methods. 
Describe in Pandas
One way in which we can do this is by using the describe function in Pandas. Using the describe function and applying it on your data frame, 
the describe function automatically computes basic statistics for all numerical variables. It shows the mean, the total number of data points, the standard deviation, 
the quantiles and the extreme values. Any NAN values are automatically skipped in these statistics. This function will give you a clear idea of the distribution of your different variables.
 You could have also categorical variables in your dataset. These are variables that can be divided up into different categories or groups and have discrete values. 
 For example; In our dataset we have the drive system as a categorical variable, which consists of the categories; forward wheel drive, rear wheel drive and four wheel drive. 
 value_counts in pandas
 One way you can summarize the categorical data is by using the function value_counts. We can change the name of the column to make it easier to read. 
 We see that we have 118 cars in the front wheel drive category, 75 cars in the rear wheel drive category, and 8 cars in the four wheel drive category. 
 BoxPlots
 Box plots are great way to visualize numeric data, since you can visualize the various distributions of the data. 
 The main features of the box plot shows are the median of the data which represents where the middle data point is. The upper quartile shows where the 75th percentile is. 
 The lower quartile shows where the 25th percentile is. The data between the upper and lower quartile represents the interquartile range. Next, you have the lower and upper extremes. 
 These are calculated as 1.5 times the interquartilre range above the 75th percentile and as 1.5 times the IQR below the 25th percentile. 
 Finally, box plots also display outliers as individual dots that occur outside the upper and lower extremes. 
 With box plots, you can easily spot outliers and also see the distribution and skewness of the data. Box plots make it easy to compare between groups. 
 In this example, using box plot we can see the distribution of different categories at the drive wheels feature over price feature. 
 We can see that the distribution of price between the rear wheel drive and the other categories are distinct, 
 but the price per front wheel drive and four wheel drive are almost indistinguishable. 
 ScatterPlots
 Oftentimes, we tend to see continuous variables in our data. 
 These data points are numbers contained in some range. For example, in our dataset price and engine size are continuous variables. 
 What if we want to understand the relationship between engine size and price. Could engine size possibly predict the price of a car? 
 One good way to visualize this is using a scatter plot. Each observation in the scatter plot is represented as a point. This plot shows the relationship between two variables. 
 The predictive variable is the variable that you were using to predict an outcome. In this case, our predictive variable is the engine size. 
 The target variable is the variable that you are trying to predict. In this case, our target variable is the price since this would be the outcome. 
 In a scatter plot, we typically set the predictive variable on the X axis or horizontal axis and we set the target variable on the Y axis or vertical axis. 
 In this case, we will thus plot the engine size on the X axis and the price on the Y axis. We are using the Matplotlib function scatter here. 
 Taking an X and a Y variable. Something to note is that it's always important to label your axes and write a general plot title, so that you know what you're looking at. 
 Now how is the variable engine size related to price? From the scatter plot, we see that as the engine size goes up the price of the car also goes up. 
 This is giving us an initial indication that there is a positive linear relationship between these two variables.

GroupBy in Python
Let us cover the basics of grouping and how this can help to transform our dataset. Assume you want to know, is there any relationship between the different types of drive system, 
forward, rear, and four-wheel drive, and the price of the vehicles? If so, which type of drive system adds the most value to a vehicle? 
It would be nice if we could group all the data by the different types of drive wheels and compare the results of these different drive wheels against each other. 
In Pandas, this can be done using the group by method. The group by method is used on categorical variables, groups the data into subsets according to the different categories of that variable. 
You can group by a single variable or you can group by multiple variables by passing in multiple variable names. 
As an example, let's say we are interested in finding the average price of vehicles and observe how they differ between different types of body styles and drive wheels variables. 
To do this, we first pick out the three data columns we are interested in, which is done in the first line of code. 
We then group the reduced data according to drive wheels and body style in the second line. Since we are interested in knowing how the average price differs across the board, 
we can take the mean of each group and append it this bit at the very end of the line too. The data is now grouped into subcategories and only the average price of each subcategory is shown. 
We can see that according to our data, rear wheel drive convertibles and rear wheel drive hard hardtops have the highest value while four wheel drive hatchbacks have the lowest value. 
A table of this form isn't the easiest to read and also not very easy to visualize. To make it easier to understand, we can transform this table to a pivot table by using the pivot method. 
In the previous table, both drive wheels and body style were listening columns. A pivot table has one variable displayed along the columns and the other variable displayed along the rows. 
Just with one line of code and by using the Panda's pivot method, we can pivot the body style variable so it is displayed along the columns 
and the drive wheels will be displayed along the rows. The price data now becomes a rectangular grid, which is easier to visualize. 
This is similar to what is usually done in Excel spreadsheets. Another way to represent the pivot table is using a heat map plot. 
Heat map takes a rectangular grid of data and assigns a color intensity based on the data value at the grid points. 
It is a great way to plot the target variable over multiple variables and through this get visual clues with the relationship between these variables and the target. 
In this example, we use pyplot's p color method to plot heat map and convert the previous pivot table into a graphical form. We specify the red-blue color scheme. 
In the output plot, each type of body style is numbered along the x-axis and each type of drive wheels is numbered along the y-axis. 
The average prices are plotted with varying colors based on their values. 
According to the color bar, we see that the top section of the heat map seems to have higher prices than the bottom section.

Correlation
we'll talk about the correlation between different variables. Correlation is a statistical metric for measuring to what extent different variables are interdependent. 
In other words, when we look at two variables over time, if one variable changes how does this affect change in the other variable? 
For example, smoking is known to be correlated to lung cancer. Since you have a higher chance of getting lung cancer if you smoke. 
In another example, there is a correlation between umbrella and rain variables where more precipitation means more people use umbrellas. 
Also, if it doesn't rain people would not carry umbrellas. Therefore, we can say that umbrellas and rain are interdependent and by definition they are correlated. 
It is important to know that correlation doesn't imply causation. 
In fact, we can say that umbrella and rain are correlated but we would not have enough information to say whether the umbrella caused the rain or the rain caused the umbrella. 
In data science we usually deal more with correlation. Let's look at the correlation between engine size and price. 
This time we'll visualize these two variables using a scatter plot and an added linear line called a regression line, which indicates the relationship between the two. 
The main goal of this plot is to see whether the engine size has any impact on the price. 
In this example, you can see that the straight line through the data points is very steep which shows that there's a positive linear relationship between the two variables. 
With increase in values of engine size, values of price go up as well and the slope of the line is positive. So there is a positive correlation between engine size and price. 
We can use seaborn.regplot to create the scatter plot. As another example, now let's look at the relationship between highway miles per gallon to see its impact on the car price. 
As we can see in this plot, when highway miles per gallon value goes up the value price goes down. Therefore there is a negative linear relationship between highway miles per gallon and price. 
Although this relationship is negative the slope of the line is steep which means that the highway miles per gallon is still a good predictor of price. 
These two variables are said to have a negative correlation. Finally, we have an example of a weak correlation. For example, both low peak RPM and high values of peak RPM have low and high prices. 
Therefore, we cannot use RPM to predict the values.

Correlation Statistics
we'll introduce you to various correlations statistical methods. One way to measure the strength of the correlation between continuous numerical variable is by using a method called Pearson correlation. 
Pearson correlation method will give you two values: the correlation coefficient and the P-value. So how do we interpret these values? For the correlation coefficient, 
a value close to 1 implies a large positive correlation, while a value close to negative 1 implies a large negative correlation, and a value close to zero implies no correlation between the variables. 
Next, the P-value will tell us how certain we are about the correlation that we calculated. For the P-value, a value less than.001 gives us a strong certainty about the correlation coefficient that we calculated. 
A value between.001 and.05 gives us moderate certainty. A value between.05 and.1 will give us a weak certainty. And a P-value larger than.1 will give us no certainty of correlation at all. 
We can say that there is a strong correlation when the correlation coefficient is close to 1 or negative 1, and the P-value is less than.001. The following plot shows data with different correlation values. 
In this example, we want to look at the correlation between the variable's horsepower and car price. See how easy you can calculate the Pearson correlation using the SI/PI stats package? 
We can see that the correlation coefficient is approximately.8, and this is close to 1. So there is a strong positive correlation. 
We can also see that the P-value is very small, much smaller than.001. And so we can conclude that we are certain about the strong positive correlation. 
Taking all variables into account, we can now create a heatmap that indicates the correlation between each of the variables with one another. 
The color scheme indicates the Pearson correlation coefficient, indicating the strength of the correlation between two variables. 
We can see a diagonal line with a dark red color, indicating that all the values on this diagonal are highly correlated. 
This makes sense because when you look closer, the values on the diagonal are the correlation of all variables with themselves, which will be always 1. 
This correlation heatmap gives us a good overview of how the different variables are related to one another and, most importantly, how these variables are related to price.

ANOVA (Analysis of Variance)
Assume that we want to analyze a categorical variable and see the correlation among different categories. For example, consider the car data set. 
The question we may ask is how different categories of the make feature, as a categorical variable, has impact on the price? The diagram shows the average price of different vehicle makes. 
We do see a trend of increasing princes as we move right along the graph. But which category in the make feature has the most, and which one has the least impact on the car price prediction? 
To analyze categorical variables, such as the make variable, we could use a method such as the ANOVA method. ANOVA is a statistical test that stands for analysis of variance. 
ANOVA can be used to find a correlation between different groups of a categorical variable. 
According to the car data set, we can use ANOVA to see if there is any difference in mean price for the different car make, such as Subaru and Honda. 
The ANOVA test returns two values, the F-test score and the p-value. The F-test calculates the ratio of variation between the group's mean over the variation within each of the sample groups. 
The p-value shows whether the obtained result is statistically significant.
Without going too deep into the details, the F-test calculates the ratio of variation between groups' means over the variation within each of the sample group means. 
This diagram illustrates a case where the F-test score would be small. Because as we can see, the variation of the prices in each group of data is way larger than the differences between the average values of each group.
Looking at this diagram, assume that Group 1 is Honda and Group 2 is Subaru. Both are the make feature categories. Since the F-score is small, the correlation between price as the target variable and the groupings is weak.
In the second diagram, we see a case where the F-test score would be large. The variation between the averages of the two groups is comparable to the variations within the two groups.
Assume that Group 1 is Jaguar and Group 2 is Honda. Both are the make feature categories. Since the F-score is large, that's the correlation is strong in this case.
Getting back to our example, the bar chart shows the average price for different categories of the make feature. 
As we can see from the bar chart, we expect a small F-score between Hondas and Subaru because there is a small difference between the average prices.
On the other hand, we can expect a large F-value between Hondas and Jaguars. Because the differences between the prices is very significant.
However from this chart, we do not know the exact variances. So let's perform an ANOVA test to see if our intuition is correct.
In the first line, we extract the make and price data, then we'll group the data by different makes. The ANOVA test can be performed in Python using the f_oneway method as the built-in function of the scipy package. 
We pass in the price data of the two car make groups that we want to compare, and it calculates the ANOVA results. The results confirm what we guessed at first. 
The prices between Hondas and Subarus are not significantly different, as the F-test score is less than 1 and p-value is larger than 0.05.
We can do the same for Honda and Jaguar. The prices between Hondas and Jaguars are significantly different since the F-score is very large. F equals 401, and the p-value is larger than 0.05. 
All in all, we can say that there is a strong correlation between a categorical variable and other variables, if the ANOVA test gives us a large F-test value and a small p-value.